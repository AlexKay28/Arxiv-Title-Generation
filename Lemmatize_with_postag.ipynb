{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "colab_type": "code",
    "id": "KhhvALLR30AU",
    "outputId": "78e90112-5f1a-4aef-b6bb-687069a7f193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy-udpipe\n",
      "  Downloading https://files.pythonhosted.org/packages/81/ff/878cb73163141ecb34e19b0008cb064cceb4ce6c1070d04d180c6a5d1d10/spacy_udpipe-0.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy-udpipe) (2.2.4)\n",
      "Collecting ufal.udpipe>=1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/72/2b8b9dc7c80017c790bb3308bbad34b57accfed2ac2f1f4ab252ff4e9cb2/ufal.udpipe-1.2.0.3.tar.gz (304kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 3.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (4.41.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (1.18.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (2.0.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (47.3.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (7.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (2.23.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (0.7.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe) (1.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->spacy-udpipe) (1.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->spacy-udpipe) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->spacy-udpipe) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->spacy-udpipe) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->spacy-udpipe) (1.24.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->spacy-udpipe) (3.1.0)\n",
      "Building wheels for collected packages: ufal.udpipe\n",
      "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp36-cp36m-linux_x86_64.whl size=5625174 sha256=4439637a803fb753248582ee622ef8bbb6bc152af0ffeeb90d3ad77c11a17f4f\n",
      "  Stored in directory: /root/.cache/pip/wheels/0c/9d/db/6d3404c33da5b7adb6c6972853efb6a27649d3ba15f7e9bebb\n",
      "Successfully built ufal.udpipe\n",
      "Installing collected packages: ufal.udpipe, spacy-udpipe\n",
      "Successfully installed spacy-udpipe-0.3.1 ufal.udpipe-1.2.0.3\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.9)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy-udpipe\n",
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFv2QFZJ3R_S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy_udpipe\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Rucf2-JE3yOf",
    "outputId": "83b6e102-4628-4ca9-8492-33c358f54f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sKLKF9vX3R_e",
    "outputId": "a64d9ede-8211-4ba5-e7c3-72b152cd8a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z83i9uih4shU"
   },
   "outputs": [],
   "source": [
    "path_train = '/content/drive/My Drive/ATG/train.csv'\n",
    "path_test = '/content/drive/My Drive/ATG/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZXSFedoa3R_o"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_train)\n",
    "ddf = pd.read_csv(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "HMMjhwzb3R_w",
    "outputId": "10adbaae-8ad6-4368-c6a0-257fd749791b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we consider the problem of utility maximizatio...</td>\n",
       "      <td>on optimal investment with processes of long o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in this paper we provide an explicit formula f...</td>\n",
       "      <td>boolean complexes for ferrers graphs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kinesin-5, also known as eg5 in vertebrates is...</td>\n",
       "      <td>relative velocity of sliding of microtubules b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we discuss the transition paths in a coupled b...</td>\n",
       "      <td>bifurcation of transition paths induced by cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two types of room temperature detectors of ter...</td>\n",
       "      <td>all-electric detectors of the polarization sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134995</th>\n",
       "      <td>we consider a minimalistic dynamic model of th...</td>\n",
       "      <td>randomly evolving idiotypic networks: structur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134996</th>\n",
       "      <td>this is an extended version of a communication...</td>\n",
       "      <td>noncommutative generalization of su(n)-princip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134997</th>\n",
       "      <td>in this paper, a new method was developed for ...</td>\n",
       "      <td>initialization of multilayer forecasting artif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134998</th>\n",
       "      <td>we propose a new approach to analyze data that...</td>\n",
       "      <td>principal arc analysis on direct product manif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134999</th>\n",
       "      <td>the design of unknown-input decoupled observer...</td>\n",
       "      <td>framework for state and unknown input estimati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abstract                                              title\n",
       "0       we consider the problem of utility maximizatio...  on optimal investment with processes of long o...\n",
       "1       in this paper we provide an explicit formula f...               boolean complexes for ferrers graphs\n",
       "2       kinesin-5, also known as eg5 in vertebrates is...  relative velocity of sliding of microtubules b...\n",
       "3       we discuss the transition paths in a coupled b...  bifurcation of transition paths induced by cou...\n",
       "4       two types of room temperature detectors of ter...  all-electric detectors of the polarization sta...\n",
       "...                                                   ...                                                ...\n",
       "134995  we consider a minimalistic dynamic model of th...  randomly evolving idiotypic networks: structur...\n",
       "134996  this is an extended version of a communication...  noncommutative generalization of su(n)-princip...\n",
       "134997  in this paper, a new method was developed for ...  initialization of multilayer forecasting artif...\n",
       "134998  we propose a new approach to analyze data that...  principal arc analysis on direct product manif...\n",
       "134999  the design of unknown-input decoupled observer...  framework for state and unknown input estimati...\n",
       "\n",
       "[135000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "QdA-HE7k42vJ",
    "outputId": "0aeb0214-e58a-48c0-ada5-60f0e8c8c21f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Most sequence transformation models use recurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The doc2vec approach was introduced as an exte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM models can vary greatly depending on sequ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A joint learning process of alignment and tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Current unsupervised image-to-image translatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>subsystem codes are the most versatile class o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>we study dirac-harmonic maps from degenerating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>in this note we study kloosterman sums twisted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>we obtain the rate of growth of long strange s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>the time evolution of a spin-1/2 particle unde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              abstract\n",
       "0    Most sequence transformation models use recurr...\n",
       "1    The doc2vec approach was introduced as an exte...\n",
       "2    LSTM models can vary greatly depending on sequ...\n",
       "3    A joint learning process of alignment and tran...\n",
       "4    Current unsupervised image-to-image translatio...\n",
       "..                                                 ...\n",
       "995  subsystem codes are the most versatile class o...\n",
       "996  we study dirac-harmonic maps from degenerating...\n",
       "997  in this note we study kloosterman sums twisted...\n",
       "998  we obtain the rate of growth of long strange s...\n",
       "999  the time evolution of a spin-1/2 particle unde...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t4NdCjVv3SAC",
    "outputId": "4e3c7c6c-9c63-48d3-96b9-6a2aecb661fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded pre-trained UDPipe model for 'en' language\n"
     ]
    }
   ],
   "source": [
    "spacy_udpipe.download(\"en\")\n",
    "nlp = spacy_udpipe.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAlU43uI3SAV"
   },
   "outputs": [],
   "source": [
    "def lemmatize_with_postag(text = \"Here we go, brothers\", nlp=nlp):\n",
    "    doc = nlp(text)\n",
    "    tagged = []\n",
    "    for token in doc:\n",
    "        lemma = token.lemma_\n",
    "        pos = token.pos_\n",
    "        if pos not in [\"PUNCT\"]: tagged.append(lemma.lower() + '_' + pos)\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewZh712J3SAd"
   },
   "outputs": [],
   "source": [
    "# train\n",
    "abstract_train = df['abstract'].apply(lemmatize_with_postag)\n",
    "title_train    = df['title'].apply(lemmatize_with_postag)\n",
    "\n",
    "# test\n",
    "abstract_test  = dff['abstract'].apply(lemmatize_with_postag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVe2kF773SAj"
   },
   "outputs": [],
   "source": [
    "# here we crate new dataset with tagget tokens! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aMvB4Iqr3SAn",
    "outputId": "4805bb56-547a-4002-f826-c89cd624c62e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[we_PRON, consider_VERB, the_DET, problem_NOUN...</td>\n",
       "      <td>[on_ADP, optimal_ADJ, investment_NOUN, with_AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[in_ADP, this_DET, paper_NOUN, we_PRON, provid...</td>\n",
       "      <td>[boolean_ADJ, complex_NOUN, for_ADP, ferrer_NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[kinesin_NOUN, 5_NUM, also_ADV, know_VERB, as_...</td>\n",
       "      <td>[relative_ADJ, velocity_NOUN, of_SCONJ, slidin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we_PRON, discuss_VERB, the_DET, transition_NO...</td>\n",
       "      <td>[bifurcation_NOUN, of_ADP, transition_NOUN, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[two_NUM, type_NOUN, of_ADP, room_NOUN, temper...</td>\n",
       "      <td>[all_ADV, electric_ADJ, detector_NOUN, of_ADP,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[we_PRON, characterize_VERB, stability_NOUN, r...</td>\n",
       "      <td>[duality_NOUN, and_CCONJ, stability_NOUN, regi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[we_PRON, present_ADJ, reconstruction_NOUN, al...</td>\n",
       "      <td>[compress_VERB, sense_VERB, for_ADP, block_NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[the_DET, successive_ADJ, projection_NOUN, alg...</td>\n",
       "      <td>[successive_ADJ, projection_NOUN, algorithm_NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[while_SCONJ, student_NOUN, may_AUX, find_VERB...</td>\n",
       "      <td>[fluid_NOUN, structure_NOUN, interaction_NOUN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[both_DET, linear_NOUN, mix_ADJ, model_NOUN, l...</td>\n",
       "      <td>[polygenic_ADJ, modeling_NOUN, with_ADP, bayes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  [we_PRON, consider_VERB, the_DET, problem_NOUN...   \n",
       "1  [in_ADP, this_DET, paper_NOUN, we_PRON, provid...   \n",
       "2  [kinesin_NOUN, 5_NUM, also_ADV, know_VERB, as_...   \n",
       "3  [we_PRON, discuss_VERB, the_DET, transition_NO...   \n",
       "4  [two_NUM, type_NOUN, of_ADP, room_NOUN, temper...   \n",
       "5  [we_PRON, characterize_VERB, stability_NOUN, r...   \n",
       "6  [we_PRON, present_ADJ, reconstruction_NOUN, al...   \n",
       "7  [the_DET, successive_ADJ, projection_NOUN, alg...   \n",
       "8  [while_SCONJ, student_NOUN, may_AUX, find_VERB...   \n",
       "9  [both_DET, linear_NOUN, mix_ADJ, model_NOUN, l...   \n",
       "\n",
       "                                               title  \n",
       "0  [on_ADP, optimal_ADJ, investment_NOUN, with_AD...  \n",
       "1  [boolean_ADJ, complex_NOUN, for_ADP, ferrer_NO...  \n",
       "2  [relative_ADJ, velocity_NOUN, of_SCONJ, slidin...  \n",
       "3  [bifurcation_NOUN, of_ADP, transition_NOUN, pa...  \n",
       "4  [all_ADV, electric_ADJ, detector_NOUN, of_ADP,...  \n",
       "5  [duality_NOUN, and_CCONJ, stability_NOUN, regi...  \n",
       "6  [compress_VERB, sense_VERB, for_ADP, block_NOU...  \n",
       "7  [successive_ADJ, projection_NOUN, algorithm_NO...  \n",
       "8  [fluid_NOUN, structure_NOUN, interaction_NOUN,...  \n",
       "9  [polygenic_ADJ, modeling_NOUN, with_ADP, bayes...  "
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train = pd.concat([abstract, title], axis=1)\n",
    "new_test  = abstract_test\n",
    "new_train, abstract_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4YAr-_h3SAt"
   },
   "outputs": [],
   "source": [
    "new_train.to_csv('/content/drive/My Drive/ATG/new_train.csv', index=False)\n",
    "new_test.to_csv('/content/drive/My Drive/ATG/new_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXty_Pup3SA6",
    "outputId": "4e38caf9-555d-4907-b060-6b2ed95b5a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATG_FINAL.ipynb\t\t     new_train.csv\t    title-generation.zip\r\n",
      "ATG.ipynb\t\t     sample_submission.csv  train.csv\r\n",
      "Lemmatize_with_postag.ipynb  test.csv\t\t    vocs.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ghHFXHC3SA9",
    "outputId": "a4a96d17-be4a-496b-e51c-a1919421a038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract,title\r\n",
      "\"['we_PRON', 'consider_VERB', 'the_DET', 'problem_NOUN', 'of_ADP', 'utility_NOUN', 'maximization_NOUN', 'for_ADP', 'investor_NOUN', 'with_ADP', 'power_NOUN', 'utility_NOUN', 'function_NOUN', 'build_NOUN', 'on_ADP', 'the_DET', 'earlier_ADJ', 'work_NOUN', 'larsen_NOUN', 'et_X', 'al._X', '2016_NUM', 'we_PRON', 'prove_VERB', 'that_SCONJ', 'the_DET', 'value_NOUN', 'of_ADP', 'the_DET', 'problem_NOUN', 'be_AUX', 'a_DET', 'frechet-differentiable_ADJ', 'function_NOUN', 'of_ADP', 'the_DET', 'drift_NOUN', 'of_ADP', 'the_DET', 'price_NOUN', 'process_NOUN', 'provide_VERB', 'that_SCONJ', 'this_DET', 'drift_NOUN', 'lie_VERB', 'in_ADP', 'a_DET', 'suitable_ADJ', 'banach_NOUN', 'space_NOUN', 'we_PRON', 'then_ADV', 'study_VERB', 'optimal_ADJ', 'investment_NOUN', 'problem_NOUN', 'with_ADP', 'non-markovian_ADJ', 'driving_NOUN', 'process_NOUN', 'in_ADP', 'such_ADJ', 'models_NOUN', 'there_PRON', 'be_VERB', 'no_DET', 'hope_NOUN', 'to_PART', 'get_VERB', 'a_DET', 'formula_NOUN', 'for_ADP', 'the_DET', 'achievable_ADJ', 'maximal_ADJ', 'utility_NOUN', 'apply_VERB', 'result_NOUN', 'of_ADP', 'the_DET', 'first_ADJ', 'part_NOUN', 'of_ADP', 'the_DET', 'paper_NOUN', 'we_PRON', 'provide_VERB', 'first_ADJ', 'order_NOUN', 'expansion_NOUN', 'for_ADP', 'certain_ADJ', 'problem_NOUN', 'involve_VERB', 'fractional_ADJ', 'brownian_ADJ', 'motion_NOUN', 'either_CCONJ', 'in_ADP', 'the_DET', 'drift_NOUN', 'or_CCONJ', 'in_ADP', 'the_DET', 'volatility_NOUN', 'we_PRON', 'also_ADV', 'point_VERB', 'out_ADP', 'how_ADV', 'asymptotic_ADJ', 'result_NOUN', 'can_AUX', 'be_AUX', 'derive_VERB', 'for_ADP', 'model_NOUN', 'with_ADP', 'strong_ADJ', 'mean_ADJ', 'reversion_NOUN']\",\"['on_ADP', 'optimal_ADJ', 'investment_NOUN', 'with_ADP', 'processis_NOUN', 'of_ADP', 'long_ADJ', 'or_CCONJ', 'negative_ADJ', 'memory_NOUN']\"\r\n",
      "\"['in_ADP', 'this_DET', 'paper_NOUN', 'we_PRON', 'provide_VERB', 'a_DET', 'explicit_ADJ', 'formula_NOUN', 'for_SCONJ', 'calculate_VERB', 'the_DET', 'boolean_ADJ', 'number_NOUN', 'of_ADP', 'a_DET', 'ferrer_NOUN', 'graph_NOUN', 'by_ADP', 'previous_ADJ', 'work_NOUN', 'of_ADP', 'the_DET', 'last_ADJ', 'two_NUM', 'author_NOUN', 'this_PRON', 'determine_VERB', 'the_DET', 'homotopy_NOUN', 'type_NOUN', 'of_ADP', 'the_DET', 'boolean_ADJ', 'complex_NOUN', 'of_ADP', 'the_DET', 'graph_NOUN', 'specialize_VERB', 'to_PART', 'staircase_VERB', 'shape_NOUN', 'we_PRON', 'show_VERB', 'that_SCONJ', 'the_DET', 'boolean_NOUN', 'number_NOUN', 'of_ADP', 'the_DET', 'associate_VERB', 'ferrer_NOUN', 'graph_NOUN', 'be_AUX', 'the_DET', 'genocchi_NOUN', 'number_NOUN', 'of_ADP', 'the_DET', 'second_ADJ', 'kind_NOUN', 'and_CCONJ', 'obtain_VERB', 'a_DET', 'relation_NOUN', 'between_ADP', 'the_DET', 'legendre_NOUN', 'stirling_NOUN', 'number_NOUN', 'and_CCONJ', 'the_DET', 'genocchi_NOUN', 'number_NOUN', 'of_ADP', 'the_DET', 'second_ADJ', 'kind_NOUN', 'in_ADP', 'another_DET', 'application_NOUN', 'we_PRON', 'compute_VERB', 'the_DET', 'boolean_ADJ', 'number_NOUN', 'of_ADP', 'a_DET', 'complete_ADJ', 'bipartite_NOUN', 'graph_NOUN', 'correspond_VERB', 'to_ADP', 'a_DET', 'rectangular_ADJ', 'ferrer_NOUN', 'shape_NOUN', 'which_PRON', 'be_AUX', 'express_VERB', 'in_ADP', 'term_NOUN', 'of_ADP', 'the_DET', 'stirling_NOUN', 'number_NOUN', 'of_ADP', 'the_DET', 'second_ADJ', 'kind_NOUN', 'finally_ADV', 'we_PRON', 'analyze_VERB', 'the_DET', 'complexity_NOUN', 'of_SCONJ', 'calculate_VERB', 'the_DET', 'boolean_ADJ', 'number_NOUN', 'of_ADP', 'a_DET', 'ferrer_NOUN', 'graph_SCONJ', 'use_VERB', 'these_DET', 'result_NOUN', 'and_CCONJ', 'show_VERB', 'that_SCONJ', 'it_PRON', 'be_AUX', 'a_DET', 'significant_ADJ', 'improvement_NOUN', 'over_SCONJ', 'calculate_VERB', 'by_ADP', 'edge_NOUN', 'recursion_NOUN']\",\"['boolean_ADJ', 'complex_NOUN', 'for_ADP', 'ferrer_NOUN', 'graph_NOUN']\"\r\n",
      "\"['kinesin_NOUN', '5_NUM', 'also_ADV', 'know_VERB', 'as_ADP', 'eg5_NOUN', 'in_ADP', 'vertebrate_NOUN', 'be_AUX', 'a_DET', 'processive_ADJ', 'motor_NOUN', 'with_ADP', '4_NUM', 'head_NOUN', 'which_PRON', 'move_VERB', 'on_ADP', 'filamentous_ADJ', 'track_NOUN', 'call_VERB', 'microtubule_NOUN', 'the_DET', 'basic_ADJ', 'function_NOUN', 'of_ADP', 'kinesin_NOUN', '5_NUM', 'be_VERB', 'to_PART', 'slide_VERB', 'apart_ADV', 'two_NUM', 'anti-parallel_ADJ', 'microtubule_NOUN', 'by_SCONJ', 'simultaneously_ADV', 'walk_VERB', 'on_ADP', 'both_CCONJ', 'the_DET', 'microtubule_NOUN', 'we_PRON', 'develop_VERB', 'a_DET', 'analytical_ADJ', 'expression_NOUN', 'for_ADP', 'the_DET', 'steady_ADJ', 'state_NOUN', 'relative_NOUN', 'velocity_NOUN', 'of_ADP', 'this_DET', 'sliding_NOUN', 'in_ADP', 'term_NOUN', 'of_ADP', 'the_DET', 'rate_NOUN', 'of_ADP', 'attachment_NOUN', 'and_CCONJ', 'detachment_NOUN', 'of_ADP', 'motor_NOUN', 'head_NOUN', 'with_ADP', 'the_DET', 'atpase_NOUN', 'site_NOUN', 'on_ADP', 'the_DET', 'microtubule_NOUN', 'we_PRON', 'first_ADV', 'analyse_VERB', 'the_DET', 'motion_NOUN', 'of_ADP', 'one_NUM', 'pair_NOUN', 'of_ADP', 'motor_NOUN', 'head_NOUN', 'on_ADP', 'one_NUM', 'microtubule_NOUN', 'and_CCONJ', 'then_ADV', 'couple_VERB', 'it_PRON', 'to_ADP', 'the_DET', 'motion_NOUN', 'of_ADP', 'the_DET', 'other_ADJ', 'pair_NOUN', 'of_ADP', 'motor_NOUN', 'head_NOUN', 'of_ADP', 'the_DET', 'same_ADJ', 'motor_NOUN', 'on_ADP', 'the_DET', 'second_ADJ', 'microtubule_NOUN', 'to_PART', 'get_VERB', 'the_DET', 'relative_ADJ', 'velocity_NOUN', 'of_SCONJ', 'sliding_VERB']\",\"['relative_ADJ', 'velocity_NOUN', 'of_SCONJ', 'sliding_VERB', 'of_ADP', 'microtubule_NOUN', 'by_ADP', 'the_DET', 'action_NOUN', 'of_ADP', 'kinesin_NOUN', '5_NUM']\"\r\n",
      "\"['we_PRON', 'discuss_VERB', 'the_DET', 'transition_NOUN', 'path_NOUN', 'in_ADP', 'a_DET', 'couple_VERB', 'bistable_ADJ', 'system_NOUN', 'consiste_NOUN', 'of_SCONJ', 'interacting_VERB', 'multiple_ADJ', 'identical_ADJ', 'bistable_ADJ', 'motif_NOUN', 'we_PRON', 'propose_VERB', 'a_DET', 'simple_ADJ', 'model_NOUN', 'of_ADP', 'couple_VERB', 'bistable_ADJ', 'gene_NOUN', 'circuit_NOUN', 'as_ADP', 'a_DET', 'example_NOUN', 'and_CCONJ', 'show_VERB', 'that_SCONJ', 'its_PRON', 'transition_NOUN', 'path_NOUN', 'be_AUX', 'bifurcat_VERB', 'we_PRON', 'then_ADV', 'derive_VERB', 'a_DET', 'criterion_NOUN', 'to_PART', 'predict_VERB', 'the_DET', 'bifurcation_NOUN', 'of_ADP', 'transition_NOUN', 'path_NOUN', 'in_ADP', 'a_DET', 'generalize_VERB', 'couple_VERB', 'bistable_ADJ', 'system_NOUN', 'we_PRON', 'confirm_VERB', 'the_DET', 'validity_NOUN', 'of_ADP', 'the_DET', 'theory_NOUN', 'for_ADP', 'the_DET', 'example_NOUN', 'system_NOUN', 'by_ADP', 'numerical_ADJ', 'simulation_NOUN', 'we_PRON', 'also_ADV', 'demonstrate_VERB', 'in_ADP', 'the_DET', 'example_NOUN', 'system_NOUN', 'that_PRON', 'if_SCONJ', 'the_DET', 'steady_ADJ', 'state_NOUN', 'of_ADP', 'individual_ADJ', 'gene_NOUN', 'circuit_NOUN', 'be_AUX', 'not_PART', 'change_VERB', 'by_ADP', 'the_DET', 'coupling_NOUN', 'the_DET', 'bifurcation_NOUN', 'pattern_NOUN', 'be_AUX', 'not_PART', 'dependent_ADJ', 'on_ADP', 'the_DET', 'number_NOUN', 'of_ADP', 'gene_NOUN', 'circuit_NOUN', 'we_PRON', 'further_ADV', 'show_VERB', 'that_SCONJ', 'the_DET', 'transition_NOUN', 'rate_NOUN', 'exponentially_ADV', 'decrease_VERB', 'with_ADP', 'the_DET', 'number_NOUN', 'of_ADP', 'gene_NOUN', 'circuit_NOUN', 'when_ADV', 'the_DET', 'transition_NOUN', 'path_NOUN', 'do_AUX', 'not_PART', 'bifurcate_VERB', 'while_SCONJ', 'a_DET', 'bifurcation_NOUN', 'facilitate_VERB', 'the_DET', 'transition_NOUN', 'by_SCONJ', 'lower_VERB', 'the_DET', 'quasi-potential_ADJ', 'energy_NOUN', 'barrier_NOUN']\",\"['bifurcation_NOUN', 'of_ADP', 'transition_NOUN', 'pat_NOUN', 'induce_VERB', 'by_ADP', 'couple_VERB', 'bistable_ADJ', 'system_NOUN']\"\r\n",
      "\"['two_NUM', 'type_NOUN', 'of_ADP', 'room_NOUN', 'temperature_NOUN', 'detector_NOUN', 'of_ADP', 'terahertz_NOUN', 'laser_NOUN', 'radiation_NOUN', 'have_AUX', 'be_AUX', 'develop_VERB', 'which_DET', 'allow_NOUN', 'in_ADP', 'a_DET', 'all_DET', 'electric_ADJ', 'manner_NOUN', 'to_PART', 'determine_VERB', 'the_DET', 'plane_NOUN', 'of_ADP', 'polarization_NOUN', 'of_ADP', 'linearly_ADV', 'polarized_VERB', 'radiation_NOUN', 'and_CCONJ', 'the_DET', 'ellipticity_NOUN', 'of_ADP', 'elliptically_ADV', 'polarized_VERB', 'radiation_NOUN', 'respectively_ADV', 'the_DET', 'operation_NOUN', 'of_ADP', 'the_DET', 'detector_NOUN', 'be_AUX', 'base_VERB', 'on_ADP', 'photogalvanic_ADJ', 'effect_NOUN', 'in_ADP', 'semiconductor_NOUN', 'quantum_ADV', 'well_ADV', 'structure_NOUN', 'of_ADP', 'low_ADJ', 'symmetry_NOUN', 'the_DET', 'photogalvanic_ADJ', 'effect_NOUN', 'have_VERB', 'sub-nanosecond_ADJ', 'time_NOUN', 'constant_NOUN', 'at_ADP', 'room_NOUN', 'temperature_NOUN', 'make_VERB', 'a_DET', 'high_ADJ', 'time_NOUN', 'resolution_NOUN', 'of_ADP', 'the_DET', 'polarization_NOUN', 'detector_NOUN', 'possible_ADJ']\",\"['all_ADV', 'electric_ADJ', 'detector_NOUN', 'of_ADP', 'the_DET', 'polarization_NOUN', 'state_NOUN', 'of_ADP', 'terahertz_NOUN', 'laser_NOUN', 'radiation_NOUN', 'extend_VERB', 'version_NOUN']\"\r\n",
      "\"['we_PRON', 'characterize_VERB', 'stability_NOUN', 'region_NOUN', 'of_ADP', 'two_NUM', 'user_NOUN', 'fad_NOUN', 'gaussian_ADJ', 'multiple_ADJ', 'access_NOUN', 'mac_NOUN', 'and_CCONJ', 'broadcast_NOUN', 'bc_NOUN', 'network_NOUN', 'with_ADP', 'centralize_VERB', 'scheduling_NOUN', 'the_DET', 'data_NOUN', 'to_PART', 'be_AUX', 'transmit_VERB', 'to_ADP', 'the_DET', 'user_NOUN', 'be_AUX', 'encod_VERB', 'into_ADP', 'codeword_NOUN', 'of_ADP', 'fix_VERB', 'length_NOUN', 'the_DET', 'rate_NOUN', 'of_ADP', 'the_DET', 'codeword_NOUN', 'use_VERB', 'be_AUX', 'restrict_VERB', 'to_ADP', 'a_DET', 'fix_VERB', 'set_NOUN', 'of_ADP', 'finite_ADJ', 'cardinality_NOUN', 'with_ADP', 'successive_ADJ', 'decoding_NOUN', 'and_CCONJ', 'interference_NOUN', 'cancellation_NOUN', 'at_ADP', 'the_DET', 'receiver_NOUN', 'we_PRON', 'find_VERB', 'the_DET', 'set_NOUN', 'of_ADP', 'arrival_NOUN', 'rate_NOUN', 'that_PRON', 'can_AUX', 'be_AUX', 'stabilize_VERB', 'over_ADP', 'the_DET', 'mac_NOUN', 'and_CCONJ', 'bc_ADJ', 'networnks_NOUN', 'in_ADP', 'mac_ADJ', 'and_CCONJ', 'bc_ADJ', 'network_NOUN', 'with_ADP', 'average_ADJ', 'power_NOUN', 'constraint_NOUN', 'we_PRON', 'observe_VERB', 'that_SCONJ', 'the_DET', 'duality_NOUN', 'property_NOUN', 'that_PRON', 'relate_VERB', 'the_DET', 'mac_NOUN', 'and_CCONJ', 'bc_ADJ', 'information_NOUN', 'theoretic_ADJ', 'capacity_NOUN', 'region_NOUN', 'extend_VERB', 'to_ADP', 'they_PRON', 'stability_NOUN', 'region_NOUN', 'as_ADV', 'well_ADV', 'in_ADP', 'mac_ADJ', 'and_CCONJ', 'bc_ADJ', 'network_NOUN', 'with_ADP', 'peak_NOUN', 'power_NOUN', 'constraint_NOUN', 'the_DET', 'union_NOUN', 'of_ADP', 'stability_NOUN', 'region_NOUN', 'of_ADP', 'dual_ADJ', 'mac_NOUN', 'network_NOUN', 'be_AUX', 'find_VERB', 'to_PART', 'be_AUX', 'strictly_ADV', 'contain_VERB', 'in_ADP', 'the_DET', 'bc_ADJ', 'stability_NOUN', 'region_NOUN']\",\"['duality_NOUN', 'and_CCONJ', 'stability_NOUN', 'region_NOUN', 'of_ADP', 'multi-rate_ADJ', 'broadcast_NOUN', 'and_CCONJ', 'multiple_ADJ', 'access_NOUN', 'network_NOUN']\"\r\n",
      "\"['we_PRON', 'present_ADJ', 'reconstruction_NOUN', 'algorithm_NOUN', 'for_ADP', 'smooth_ADJ', 'signal_NOUN', 'with_ADP', 'block_NOUN', 'sparsity_NOUN', 'from_ADP', 'they_PRON', 'compressed_VERB', 'measurement_NOUN', 'we_PRON', 'tackle_VERB', 'the_DET', 'issue_NOUN', 'of_SCONJ', 'varying_VERB', 'group_NOUN', 'size_NOUN', 'via_ADP', 'group_NOUN', 'sparse_NOUN', 'least_ADV', 'absolute_ADJ', 'shrinkage_NOUN', 'selection_NOUN', 'operator_NOUN', 'lasso_X', 'as_ADV', 'well_ADV', 'as_ADP', 'via_ADP', 'latent_ADJ', 'group_NOUN', 'lasso_NOUN', 'regularization_NOUN', 'we_PRON', 'achieve_VERB', 'smoothness_NOUN', 'in_ADP', 'the_DET', 'signal_NOUN', 'via_ADP', 'fusion_NOUN', 'we_PRON', 'develop_VERB', 'low_ADJ', 'complexity_NOUN', 'solver_NOUN', 'for_ADP', 'we_PRON', 'propose_VERB', 'formulation_NOUN', 'through_ADP', 'the_DET', 'alternating_NOUN', 'direction_NOUN', 'method_NOUN', 'of_ADP', 'multiplier_NOUN']\",\"['compress_VERB', 'sense_VERB', 'for_ADP', 'block_NOUN', 'sparse_NOUN', 'smooth_ADJ', 'signal_NOUN']\"\r\n",
      "\"['the_DET', 'successive_ADJ', 'projection_NOUN', 'algorithm_NOUN', 'spa_NOUN', 'be_AUX', 'a_DET', 'fast_ADJ', 'algorithm_NOUN', 'to_PART', 'tackle_VERB', 'separable_ADJ', 'nonnegative_ADJ', 'matrix_NOUN', 'factorization_NOUN', 'nmf_NOUN', 'give_VERB', 'a_DET', 'nonnegative_ADJ', 'data_NOUN', 'matrix_NOUN', '$_SYM', 'x_SYM', '$_SYM', 'spa_NOUN', 'identify_VERB', 'a_DET', 'index_NOUN', 'set_NOUN', '$_SYM', '\\\\mathcal_ADJ', '{k_NOUN', '}$_NOUN', 'such_ADJ', 'that_SCONJ', 'there_PRON', 'exist_VERB', 'a_DET', 'nonnegative_ADJ', 'matrix_NOUN', '$h$_VERB', 'with_ADP', '$_SYM', 'x_SYM', '\\\\approx_SYM', 'x_SYM', ':,\\\\mathcal_ADJ', '{k})_SYM', 'h$._SYM', 'spa_NOUN', 'have_AUX', 'be_AUX', 'successfully_ADV', 'use_VERB', 'as_ADP', 'a_DET', 'pure_ADJ', '-pixel_NOUN', 'search_NOUN', 'algorithm_NOUN', 'in_ADP', 'hyperspectral_ADJ', 'unmixing_NOUN', 'and_CCONJ', 'for_ADP', 'anchor_NOUN', 'word_NOUN', 'selection_NOUN', 'in_ADP', 'document_NOUN', 'classification_NOUN', 'moreover_ADV', 'spa_NOUN', 'be_AUX', 'provably_ADV', 'robust_ADJ', 'in_ADP', 'low_ADJ', 'noise_NOUN', 'setting_NOUN', 'the_DET', 'main_ADJ', 'drawback_NOUN', 'of_ADP', 'spa_NOUN', 'be_VERB', 'that_SCONJ', 'it_PRON', 'be_AUX', 'not_PART', 'robust_ADJ', 'to_ADP', 'outlier_NOUN', 'and_CCONJ', 'do_AUX', 'not_PART', 'take_VERB', 'the_DET', 'data_NOUN', 'fit_VERB', 'term_NOUN', 'into_ADP', 'account_NOUN', 'when_ADV', 'select_VERB', 'the_DET', 'index_NOUN', 'in_ADP', '$_SYM', '\\\\mathcal_ADJ', 'k_NOUN', '}$._NOUN', 'in_ADP', 'this_DET', 'paper_NOUN', 'we_PRON', 'propose_VERB', 'a_DET', 'new_ADJ', 'spa_NOUN', 'variant_NOUN', 'dub_VERB', 'robust_ADJ', 'spa_NOUN', 'rspa_NOUN', 'that_PRON', 'be_AUX', 'robust_ADJ', 'to_ADP', 'outlier_NOUN', 'while_SCONJ', 'still_ADV', 'be_AUX', 'provably_ADV', 'robust_ADJ', 'in_ADP', 'low_ADJ', 'noise_NOUN', 'setting_NOUN', 'and_CCONJ', 'that_PRON', 'take_VERB', 'into_ADP', 'account_NOUN', 'the_DET', 'reconstruction_NOUN', 'error_NOUN', 'for_SCONJ', 'select_VERB', 'the_DET', 'index_NOUN', 'in_ADP', '$_SYM', '\\\\mathcal_ADJ', 'k_NOUN', 'we_PRON', 'illustrate_VERB', 'the_DET', 'effectiveness_NOUN', 'of_ADP', 'rspa_NOUN', 'on_ADP', 'synthetic_ADJ', 'data_NOUN', 'set_NOUN', 'and_CCONJ', 'hyperspectral_ADJ', 'image_NOUN']\",\"['successive_ADJ', 'projection_NOUN', 'algorithm_NOUN', 'robust_ADJ', 'to_ADP', 'outlier_NOUN']\"\r\n",
      "\"['while_SCONJ', 'student_NOUN', 'may_AUX', 'find_VERB', 'spline_NUM', 'interpolation_NOUN', 'easily_ADV', 'digestible_ADJ', 'base_VERB', 'on_ADP', 'they_PRON', 'familiarity_NOUN', 'with_ADP', 'continuity_NOUN', 'of_ADP', 'a_DET', 'function_NOUN', 'and_CCONJ', 'its_PRON', 'derivative_NOUN', 'some_DET', 'of_ADP', 'its_PRON', 'inherent_ADJ', 'value_NOUN', 'may_AUX', 'be_AUX', 'miss_VERB', 'when_ADV', 'student_NOUN', 'only_ADV', 'see_VERB', 'it_PRON', 'apply_VERB', 'to_PART', 'standard_VERB', 'data_NOUN', 'interpolation_NOUN', 'exercise_NOUN', 'in_ADP', 'this_DET', 'paper_NOUN', 'we_PRON', 'offer_VERB', 'alternative_NOUN', 'where_ADV', 'student_NOUN', 'can_AUX', 'qualitatively_ADV', 'and_CCONJ', 'quantitatively_ADV', 'witness_VERB', 'the_DET', 'result_VERB', 'dynamical_ADJ', 'difference_NOUN', 'when_ADV', 'objects_NOUN', 'be_AUX', 'drive_VERB', 'through_ADP', 'a_DET', 'fluid_NOUN', 'use_VERB', 'different_ADJ', 'spline_NOUN', 'interpolation_NOUN', 'methods_NOUN', 'they_PRON', 'say_VERB', 'see_VERB', 'be_AUX', 'believe_VERB', 'here_ADV', 'we_PRON', 'showcase_VERB', 'the_DET', 'difference_NOUN', 'between_ADP', 'linear_NOUN', 'and_CCONJ', 'cubic_ADJ', 'spline_NOUN', 'interpolation_NOUN', 'use_VERB', 'example_NOUN', 'from_ADP', 'fluid_NOUN', 'pumping_NOUN', 'and_CCONJ', 'aquatic_ADJ', 'locomotion_NOUN', 'moreover_ADV', 'student_NOUN', 'can_AUX', 'define_VERB', 'they_PRON', 'own_ADJ', 'interpolation_NOUN', 'function_NOUN', 'and_CCONJ', 'visualize_VERB', 'the_DET', 'dynamics_NOUN', 'unfold_ADJ', 'to_PART', 'solve_VERB', 'the_DET', 'fluid_NOUN', 'structure_NOUN', 'interaction_NOUN', 'system_NOUN', 'the_DET', 'open_ADJ', 'source_NOUN', 'software_NOUN', 'ib2d_NOUN', 'be_AUX', 'use_VERB', 'in_ADP', 'that_DET', 'vein_NOUN', 'all_DET', 'simulation_NOUN', 'code_NOUN', 'analysis_NOUN', 'script_NOUN', 'and_CCONJ', 'movie_NOUN', 'be_AUX', 'provide_VERB', 'for_ADP', 'streamlined_VERB', 'use_NOUN']\",\"['fluid_NOUN', 'structure_NOUN', 'interaction_NOUN', 'for_ADP', 'the_DET', 'classroom_NOUN', 'interpolation_NOUN', 'heart_NOUN', 'and_CCONJ', 'swimm_ADJ']\"\r\n"
     ]
    }
   ],
   "source": [
    "! head new_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYgKJ0kC3SBA"
   },
   "outputs": [],
   "source": [
    "! head new_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D09EQa1X3SBF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lemmatize_with_postag.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
